<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=640">

    <link rel="stylesheet" href="stylesheets/core.css" media="screen">
    <link rel="stylesheet" href="stylesheets/mobile.css" media="handheld, only screen and (max-device-width:640px)">
    <link rel="stylesheet" href="stylesheets/github-light.css">

    <script type="text/javascript" src="javascripts/modernizr.js"></script>
    <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script type="text/javascript" src="javascripts/headsmart.min.js"></script>
    <script type="text/javascript">
      $(document).ready(function () {
        $('#main_content').headsmart()
      })
    </script>
    <title>Louis.GitHub.blogs by LouisProgress</title>
  </head>

  <body>
    <a id="forkme_banner" href="https://github.com/LouisProgress/louis.github.blogs">View on GitHub</a>
    <div class="shell">

      <header>
        <span class="ribbon-outer">
          <span class="ribbon-inner">
            <h1>Louis.GitHub.blogs</h1>
            <h2>WebCollector 爬虫框架入门之常用爬虫介绍（一）</h2>
          </span>
          <span class="left-tail"></span>
          <span class="right-tail"></span>
        </span>
      </header>

      <section id="downloads">
        <span class="inner">
          <a href="https://github.com/LouisProgress/louis.github.blogs/zipball/master" class="zip"><em>download</em> .ZIP</a><a href="https://github.com/LouisProgress/louis.github.blogs/tarball/master" class="tgz"><em>download</em> .TGZ</a>
        </span>
      </section>


      <span class="banner-fix"></span>


      <section id="main_content">
        <h2>
<a id="一-webcollector-爬虫简介" class="anchor" href="#%E4%B8%80-webcollector-%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>一、 WebCollector 爬虫简介</h2>

<p>爬虫，基本可以分3类：
1.分布式爬虫：Nutch
2.JAVA单机爬虫：Crawler4j、WebMagic、WebCollector
3. 非JAVA单机爬虫：scrapy</p>

<h3>
<a id="第一类分布式爬虫" class="anchor" href="#%E7%AC%AC%E4%B8%80%E7%B1%BB%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>第一类:分布式爬虫</h3>

<p>爬虫使用分布式，主要是解决两个问题：</p>

<p>1)海量URL管理</p>

<p>2)网速</p>

<p>现在比较流行的分布式爬虫，是Apache的Nutch。但是对于大多数用户来说，Nutch是这几类爬虫里，最不好的选择，理由如下：</p>

<p>1)Nutch是为搜索引擎设计的爬虫，大多数用户是需要一个做精准数据爬取（精抽取）的爬虫。Nutch运行的一套流程里，有三分之二是为了搜索引擎而设计的。对精抽取没有太大的意义。也就是说，用Nutch做数据抽取，会浪费很多的时间在不必要的计算上。而且如果你试图通过对Nutch进行二次开发，来使得它适用于精抽取的业务，基本上就要破坏Nutch的框架，把Nutch改的面目全非，有修改Nutch的能力，真的不如自己重新写一个分布式爬虫框架了。</p>

<p>2)Nutch依赖hadoop运行，hadoop本身会消耗很多的时间。如果集群机器数量较少，爬取速度反而不如单机爬虫快。</p>

<p>3)Nutch虽然有一套插件机制，而且作为亮点宣传。可以看到一些开源的Nutch插件，提供精抽取的功能。但是开发过Nutch插件的人都知道，Nutch的插件系统有多蹩脚。利用反射的机制来加载和调用插件，使得程序的编写和调试都变得异常困难，更别说在上面开发一套复杂的精抽取系统了。而且Nutch并没有为精抽取提供相应的插件挂载点。Nutch的插件有只有五六个挂载点，而这五六个挂载点都是为了搜索引擎服务的，并没有为精抽取提供挂载点。大多数Nutch的精抽取插件，都是挂载在“页面解析”(parser)这个挂载点的，这个挂载点其实是为了解析链接（为后续爬取提供URL），以及为搜索引擎提供一些易抽取的网页信息(网页的meta信息、text文本)。</p>

<p>4)用Nutch进行爬虫的二次开发，爬虫的编写和调试所需的时间，往往是单机爬虫所需的十倍时间不止。了解Nutch源码的学习成本很高，何况是要让一个团队的人都读懂Nutch源码。调试过程中会出现除程序本身之外的各种问题(hadoop的问题、hbase的问题)。</p>

<p>5)很多人说Nutch2有gora，可以持久化数据到avro文件、hbase、mysql等。很多人其实理解错了，这里说的持久化数据，是指将URL信息（URL管理所需要的数据）存放到avro、hbase、mysql。并不是你要抽取的结构化数据。其实对大多数人来说，URL信息存在哪里无所谓。</p>

<p>6)Nutch2的版本目前并不适合开发。官方现在稳定的Nutch版本是nutch2.2.1，但是这个版本绑定了gora-0.3。如果想用hbase配合nutch（大多数人用nutch2就是为了用hbase)，只能使用0.90版本左右的hbase，相应的就要将hadoop版本降到hadoop 0.2左右。而且nutch2的官方教程比较有误导作用，Nutch2的教程有两个，分别是Nutch1.x和Nutch2.x，这个Nutch2.x官网上写的是可以支持到hbase 0.94。但是实际上，这个Nutch2.x的意思是Nutch2.3之前、Nutch2.2.1之后的一个版本，这个版本在官方的SVN中不断更新。而且非常不稳定（一直在修改）。</p>

<p>所以，如果你不是要做搜索引擎，尽量不要选择Nutch作为爬虫。有些团队就喜欢跟风，非要选择Nutch来开发精抽取的爬虫，其实是冲着Nutch的名气（Nutch作者是Doug Cutting），当然最后的结果往往是项目延期完成。</p>

<p>如果你是要做搜索引擎，Nutch1.x是一个非常好的选择。Nutch1.x和solr或者es配合，就可以构成一套非常强大的搜索引擎了。如果非要用Nutch2的话，建议等到Nutch2.3发布再看。目前的Nutch2是一个非常不稳定的版本。</p>

<h3>
<a id="第二类java单机爬虫" class="anchor" href="#%E7%AC%AC%E4%BA%8C%E7%B1%BBjava%E5%8D%95%E6%9C%BA%E7%88%AC%E8%99%AB" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>第二类:JAVA单机爬虫</h3>

<p>这里把JAVA爬虫单独分为一类，是因为JAVA在网络爬虫这块的生态圈是非常完善的。相关的资料也是最全的。这里可能有争议，我只是随便扯淡。</p>

<p>其实开源网络爬虫（框架）的开发非常简单，难问题和复杂的问题都被以前的人解决了（比如DOM树解析和定位、字符集检测、海量URL去重），可以说是毫无技术含量。包括Nutch，其实Nutch的技术难点是开发hadoop，本身代码非常简单。网络爬虫从某种意义来说，类似遍历本机的文件，查找文件中的信息。没有任何难度可言。之所以选择开源爬虫框架，就是为了省事。比如爬虫的URL管理、线程池之类的模块，谁都能做，但是要做稳定也是需要一段时间的调试和修改的。</p>

<p>对于爬虫的功能来说。用户比较关心的问题往往是：</p>

<p>1）爬虫支持多线程么、爬虫能用代理么、爬虫会爬取重复数据么、爬虫能爬取JS生成的信息么？</p>

<p>不支持多线程、不支持代理、不能过滤重复URL的，那都不叫开源爬虫，那叫循环执行http请求。</p>

<p>能不能爬js生成的信息和爬虫本身没有太大关系。爬虫主要是负责遍历网站和下载页面。爬js生成的信息和网页信息抽取模块有关，往往需要通过模拟浏览器(htmlunit,selenium)来完成。这些模拟浏览器，往往需要耗费很多的时间来处理一个页面。所以一种策略就是，使用这些爬虫来遍历网站，遇到需要解析的页面，就将网页的相关信息提交给模拟浏览器，来完成JS生成信息的抽取。</p>

<p>2）爬虫可以爬取ajax信息么？</p>

<p>网页上有一些异步加载的数据，爬取这些数据有两种方法：使用模拟浏览器（问题1中描述过了），或者分析ajax的http请求，自己生成ajax请求的url，获取返回的数据。如果是自己生成ajax请求，使用开源爬虫的意义在哪里？其实是要用开源爬虫的线程池和URL管理功能（比如断点爬取）。</p>

<p>如果我已经可以生成我所需要的ajax请求（列表），如何用这些爬虫来对这些请求进行爬取？</p>

<p>爬虫往往都是设计成广度遍历或者深度遍历的模式，去遍历静态或者动态页面。爬取ajax信息属于deep web（深网）的范畴，虽然大多数爬虫都不直接支持。但是也可以通过一些方法来完成。比如WebCollector使用广度遍历来遍历网站。爬虫的第一轮爬取就是爬取种子集合(seeds)中的所有url。简单来说，就是将生成的ajax请求作为种子，放入爬虫。用爬虫对这些种子，进行深度为1的广度遍历（默认就是广度遍历）。</p>

<p>3）爬虫怎么爬取要登陆的网站？</p>

<p>这些开源爬虫都支持在爬取时指定cookies，模拟登陆主要是靠cookies。至于cookies怎么获取，不是爬虫管的事情。你可以手动获取、用http请求模拟登陆或者用模拟浏览器自动登陆获取cookie。</p>

<p>4）爬虫怎么抽取网页的信息？</p>

<p>开源爬虫一般都会集成网页抽取工具。主要支持两种规范：CSS SELECTOR和XPATH。至于哪个好，这里不评价。</p>

<p>5）爬虫怎么保存网页的信息？</p>

<p>有一些爬虫，自带一个模块负责持久化。比如webmagic，有一个模块叫pipeline。通过简单地配置，可以将爬虫抽取到的信息，持久化到文件、数据库等。还有一些爬虫，并没有直接给用户提供数据持久化的模块。比如crawler4j和webcollector。让用户自己在网页处理模块中添加提交数据库的操作。至于使用pipeline这种模块好不好，就和操作数据库使用ORM好不好这个问题类似，取决于你的业务。</p>

<p>6）爬虫被网站封了怎么办？</p>

<p>爬虫被网站封了，一般用多代理（随机代理）就可以解决。但是这些开源爬虫一般没有直接支持随机代理的切换。所以用户往往都需要自己将获取的代理，放到一个全局数组中，自己写一个代理随机获取（从数组中）的代码。</p>

<p>7）网页可以调用爬虫么？</p>

<p>爬虫的调用是在Web的服务端调用的，平时怎么用就怎么用，这些爬虫都可以使用。</p>

<p>8）爬虫速度怎么样？</p>

<p>单机开源爬虫的速度，基本都可以讲本机的网速用到极限。爬虫的速度慢，往往是因为用户把线程数开少了、网速慢，或者在数据持久化时，和数据库的交互速度慢。而这些东西，往往都是用户的机器和二次开发的代码决定的。这些开源爬虫的速度，都很可以。</p>

<p>9）明明代码写对了，爬不到数据，是不是爬虫有问题，换个爬虫能解决么？</p>

<p>如果代码写对了，又爬不到数据，换其他爬虫也是一样爬不到。遇到这种情况，要么是网站把你封了，要么是你爬的数据是javascript生成的。爬不到数据通过换爬虫是不能解决的。</p>

<p>10）哪个爬虫可以判断网站是否爬完、那个爬虫可以根据主题进行爬取？</p>

<p>爬虫无法判断网站是否爬完，只能尽可能覆盖。</p>

<p>至于根据主题爬取，爬虫之后把内容爬下来才知道是什么主题。所以一般都是整个爬下来，然后再去筛选内容。如果嫌爬的太泛，可以通过限制URL正则等方式，来缩小一下范围。</p>

<p>11）哪个爬虫的设计模式和构架比较好？</p>

<p>设计模式纯属扯淡。说软件设计模式好的，都是软件开发完，然后总结出几个设计模式。设计模式对软件开发没有指导性作用。用设计模式来设计爬虫，只会使得爬虫的设计更加臃肿。</p>

<p>至于构架，开源爬虫目前主要是细节的数据结构的设计，比如爬取线程池、任务队列，这些大家都能控制好。爬虫的业务太简单，谈不上什么构架。</p>

<p>所以对于JAVA开源爬虫，我觉得，随便找一个用的顺手的就可以。如果业务复杂，拿哪个爬虫来，都是要经过复杂的二次开发，才可以满足需求。</p>

<h3>
<a id="第三类非java单机爬虫" class="anchor" href="#%E7%AC%AC%E4%B8%89%E7%B1%BB%E9%9D%9Ejava%E5%8D%95%E6%9C%BA%E7%88%AC%E8%99%AB" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>第三类:非JAVA单机爬虫</h3>

<p>在非JAVA语言编写的爬虫中，有很多优秀的爬虫。这里单独提取出来作为一类，并不是针对爬虫本身的质量进行讨论，而是针对larbin、scrapy这类爬虫，对开发成本的影响。</p>

<p>先说python爬虫，python可以用30行代码，完成JAVA 50行代码干的任务。python写代码的确快，但是在调试代码的阶段，python代码的调试往往会耗费远远多于编码阶段省下的时间。使用python开发，要保证程序的正确性和稳定性，就需要写更多的测试模块。当然如果爬取规模不大、爬取业务不复杂，使用scrapy这种爬虫也是蛮不错的，可以轻松完成爬取任务。</p>
      </section>

      <footer>
        <span class="ribbon-outer">
          <span class="ribbon-inner">
            <p>this project by <a href="https://github.com/LouisProgress">LouisProgress</a> can be found on <a href="https://github.com/LouisProgress/louis.github.blogs">GitHub</a></p>
          </span>
          <span class="left-tail"></span>
          <span class="right-tail"></span>
        </span>
        <p>Generated with <a href="https://pages.github.com">GitHub Pages</a> using Merlot</p>
        <span class="octocat"></span>
      </footer>

    </div>

    
  </body>
</html>
